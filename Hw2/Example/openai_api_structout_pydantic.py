"""
OpenAI API Structured Output with Pydantic Example

What this does:
    Shows how to get structured, validated data from GPT using Pydantic models.
    Instead of just getting text back, you define what data format you want
    (like a list of objects with specific fields), and the API returns exactly that.

What you'll need:
    - openai: Library to connect to OpenAI's API
    - dotenv: Loads your API key from a .env file
    - pydantic: Creates data models that automatically validate the API response
        - BaseModel: Used to define your data structure
        - Field: Adds descriptions and validation rules to each field
        - ConfigDict: Configures how the model behaves
    - typing.List: Specifies a field should be a list
    - os: Reads environment variables (like your API key)

What you'll learn:
    - How to define a Pydantic model (example: Roman Emperor data)
    - How Pydantic automatically creates a JSON schema for the API
    - How to ensure the API response matches your exact requirements
    - How to access the data safely with type checking
    - How to calculate the cost of your API call
"""

from openai import OpenAI
from dotenv import load_dotenv
from pydantic import BaseModel, Field, ConfigDict
from typing import List
import os


# Pydantic models (v2)
class Emperor(BaseModel):
    model_config = ConfigDict(extra="forbid")  # -> additionalProperties: false
    name: str = Field(..., description="Name of the emperor")
    first_year: int = Field(..., description="First year of reign (use negative for BC)")
    last_year: int = Field(..., description="Last year of reign (use negative for BC)")
    why_ended: str = Field(..., description="A concise reason for why their reign ended")


class RomanEmperors(BaseModel):
    model_config = ConfigDict(extra="forbid")  # -> additionalProperties: false
    emperors: List[Emperor] = Field(..., description="List of each emperor")


# Setup
load_dotenv("../../.env")
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Build JSON Schema from Pydantic
schema = RomanEmperors.model_json_schema()
# Some SDKs are strict about having no top-level $schema key; safe to remove:
schema.pop("$schema", None)

# Call the model with the schema
resp = client.chat.completions.create(
    model="gpt-5-nano",
    messages=[
        {"role": "system", "content": "You are an expert in ancient Roman history."},
        {"role": "user", "content": "Generate a complete list of emperors, beginning with the fall of the republic."}
    ],
    reasoning_effort="low",
    response_format={
        "type": "json_schema",
        "json_schema": {
            "name": "roman_emperors",
            "schema": schema,   # generated by Pydantic
            "strict": True
        }
    }
)

# Validate/parse with Pydantic
content = resp.choices[0].message.content  # JSON string from the model
data = RomanEmperors.model_validate_json(content)

# Use the parsed result
print("Model's Formatted Response:")
for e in data.emperors:
    print(e.name)
    print(f"\t First Year: {e.first_year}")
    print(f"\t Last Year:  {e.last_year}")
    print(f"\t Why Ended:  {e.why_ended}")

print()
print(f"Input Tokens:  {resp.usage.prompt_tokens}")
print(f"Output Tokens: {resp.usage.completion_tokens}")
print(f"Cost: ${resp.usage.prompt_tokens * 0.05 / 1E6 + resp.usage.completion_tokens * 0.4 / 1E6}")
